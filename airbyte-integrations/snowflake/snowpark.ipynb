{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c809474",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install snowflake-snowpark-python\n",
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e0be86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from snowflake.snowpark import Session\n",
    "from snowflake.snowpark.functions import sproc\n",
    "import snowflake.snowpark\n",
    "from snowflake.snowpark.types import IntegerType\n",
    "import boto3\n",
    "import logging\n",
    "import sys\n",
    "import snowflake.snowpark\n",
    "from snowflake.snowpark.functions import sproc\n",
    "from snowflake.snowpark.types import IntegerType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b052b39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load snowflake secrets and. create the session\n",
    "# Snowflake Oauth integration test account\n",
    "with open(\"./secrets/GZ45853.json\", \"r\") as f:\n",
    "    connection_parameters = json.loads(f.read())\n",
    "test_session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68efcd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = \"airbyte.alex\"\n",
    "connector = \"source-pokeapi\"\n",
    "aws_role_arn = \"arn:aws:iam::168714685353:role/snowflake-api-gateway-test\"\n",
    "api_gateway_url = \"https://w72cfwmned.execute-api.us-west-1.amazonaws.com/stage\"\n",
    "api_integration_name = f\"{connector}_api_integration\".replace(\"-\", \"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d983f573",
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8acd8c2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [create or REPLACE stage mystage url = 's3://airbyte.alex']\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    }
   ],
   "source": [
    "# Create a stage to store the code\n",
    "create_stage_result = test_session.sql(f\"create or REPLACE stage mystage url = 's3://{bucket}'\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "296fcbab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [describe integration source_pokeapi_api_integration]\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(property='ENABLED', property_type='Boolean', property_value='true', property_default='false'),\n",
       " Row(property='API_KEY', property_type='String', property_value='', property_default=''),\n",
       " Row(property='API_PROVIDER', property_type='String', property_value='AWS_API_GATEWAY', property_default=''),\n",
       " Row(property='API_AWS_IAM_USER_ARN', property_type='String', property_value='arn:aws:iam::147018273998:user/6o3f-s-ohss5467', property_default=''),\n",
       " Row(property='API_AWS_ROLE_ARN', property_type='String', property_value='arn:aws:iam::168714685353:role/snowflake-api-gateway-test', property_default=''),\n",
       " Row(property='API_AWS_EXTERNAL_ID', property_type='String', property_value='GZ45853_SFCRole=2_Q9B1fFjAUub69Ifq6flHOJwBZ/8=', property_default=''),\n",
       " Row(property='API_ALLOWED_PREFIXES', property_type='List', property_value='https://w72cfwmned.execute-api.us-west-1.amazonaws.com/stage', property_default='[]'),\n",
       " Row(property='API_BLOCKED_PREFIXES', property_type='List', property_value='', property_default='[]'),\n",
       " Row(property='COMMENT', property_type='String', property_value='', property_default='')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the integration\n",
    "# WARNING: The gateway's trust relationship must be updated if the api integration is recreated.\n",
    "def create_api_integration(api_integration_name, aws_role_arn, api_gateway_url):\n",
    "    return test_session.sql(f\"\"\"\n",
    "    create or replace api integration {api_integration_name}\n",
    "      api_provider = aws_api_gateway\n",
    "      api_aws_role_arn = '{aws_role_arn}'\n",
    "      api_allowed_prefixes = ('{api_gateway_url}')\n",
    "      enabled = true;\n",
    "    \"\"\").collect()\n",
    "def describe_api_integration(api_integration_name):\n",
    "    return test_session.sql(f\"describe integration {api_integration_name}\").collect()\n",
    "\n",
    "\n",
    "#create_api_integration(api_integration_name, aws_role_arn, api_gateway_url)\n",
    "describe_api_integration(api_integration_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8adf3f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [create or replace function source_request_translator(event object) returns objec...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "[Row(status='Function SOURCE_REQUEST_TRANSLATOR successfully created.')]\n",
      "INFO:snowflake.connector.cursor:query: [create or replace function source_response_translator(event object) returns obje...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "[Row(status='Function SOURCE_RESPONSE_TRANSLATOR successfully created.')]\n",
      "INFO:snowflake.connector.cursor:query: [create or replace external function source_pokeapi_external_function(body varcha...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "[Row(status='Function SOURCE_POKEAPI_EXTERNAL_FUNCTION successfully created.')]\n",
      "INFO:snowflake.connector.cursor:query: [describe function source_pokeapi_external_function (varchar, varchar)]\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(property='signature', value='(BODY VARCHAR, URLSUFFIX VARCHAR)'),\n",
       " Row(property='returns', value='VARIANT'),\n",
       " Row(property='language', value='EXTERNAL'),\n",
       " Row(property='null handling', value='CALLED ON NULL INPUT'),\n",
       " Row(property='volatility', value='VOLATILE'),\n",
       " Row(property='body', value='https://w72cfwmned.execute-api.us-west-1.amazonaws.com/stage'),\n",
       " Row(property='headers', value='null'),\n",
       " Row(property='context_headers', value='null'),\n",
       " Row(property='max_batch_rows', value='not set'),\n",
       " Row(property='request_translator', value='ALEX_TEST.PUBLIC.SOURCE_REQUEST_TRANSLATOR'),\n",
       " Row(property='response_translator', value='ALEX_TEST.PUBLIC.SOURCE_RESPONSE_TRANSLATOR'),\n",
       " Row(property='compression', value='AUTO')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create external function and translators\n",
    "\n",
    "request_translator_name = \"source_request_translator\"\n",
    "response_translator_name = \"source_response_translator\"\n",
    "external_function_name = f\"{connector.replace('-', '_')}_external_function\"\n",
    "\n",
    "# Create request_translator\n",
    "# The same request translator can be used across multiple connectors\n",
    "def create_request_translator(request_translator_name):\n",
    "    return test_session.sql(f\"\"\"\n",
    "    create or replace function {request_translator_name}(event object)\n",
    "    returns object\n",
    "    language javascript as\n",
    "    '\n",
    "    body = EVENT.body.data[0][1]\n",
    "    suffixUrl = EVENT.body.data[0][2]\n",
    "    return {{ \"body\": body, \"urlSuffix\": suffixUrl}};\n",
    "    ';\n",
    "    \"\"\").collect()\n",
    "\n",
    "  \n",
    "# Create response translator\n",
    "# The same response translator can be used across multiple connectors\n",
    "def create_response_translator(response_translator_name):\n",
    "    return test_session.sql(f\"\"\"\n",
    "    create or replace function {response_translator_name}(event object)\n",
    "    returns object\n",
    "    language javascript as\n",
    "    '\n",
    "    return {{ \"body\": {{ \"data\" : [[0, EVENT]] }}}};\n",
    "    ';\n",
    "    \"\"\").collect()\n",
    "\n",
    "# Create external function\n",
    "# One external function per connector\n",
    "def create_external_function(external_function_name,\n",
    "                             api_integration_name,\n",
    "                             request_translator_name,\n",
    "                             response_translator_name,\n",
    "                             api_gateway_url):\n",
    "    query = f\"\"\"\n",
    "    create or replace external function {external_function_name}(body varchar, urlSuffix varchar)\n",
    "      returns variant\n",
    "      api_integration = {api_integration_name}\n",
    "      request_translator = {request_translator_name}\n",
    "      response_translator = {response_translator_name}\n",
    "      as '{api_gateway_url}';\n",
    "    \"\"\"\n",
    "    return test_session.sql(query).collect()\n",
    "\n",
    "def describe_external_function(external_function_name):\n",
    "    query = f\"describe function {external_function_name} (varchar, varchar)\"\n",
    "    return test_session.sql(query).collect()\n",
    "\n",
    "print(create_request_translator(request_translator_name))\n",
    "print(create_response_translator(response_translator_name))\n",
    "print(create_external_function(external_function_name, api_integration_name, request_translator_name, response_translator_name, api_gateway_url))\n",
    "\n",
    "describe_external_function(external_function_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc89ce53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [CREATE DATABASE if not exists source_pokeapi_app;]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [CREATE SCHEMA if not exists source_pokeapi_app.app_schema;]\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    }
   ],
   "source": [
    "# Create a database to be used by the application\n",
    "def create_database(source_name):\n",
    "    database_query = f\"\"\"\n",
    "    CREATE DATABASE if not exists {source_name}_app;\n",
    "    \"\"\"\n",
    "    schema_query = f\"\"\"\n",
    "    CREATE SCHEMA if not exists {source_name}_app.app_schema;\n",
    "    \"\"\"\n",
    "    test_session.sql(database_query).collect()\n",
    "    test_session.sql(schema_query).collect()\n",
    "create_database(\"source_pokeapi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "297ce2ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files_to_load(connector):\n",
    "    s3_paginator = boto3.client('s3').get_paginator('list_objects_v2')\n",
    "\n",
    "    def keys(bucket_name, prefix='/', delimiter='/', start_after=''):\n",
    "        prefix = prefix[1:] if prefix.startswith(delimiter) else prefix\n",
    "        start_after = (start_after or prefix) if prefix.endswith(delimiter) else start_after\n",
    "        for page in s3_paginator.paginate(Bucket=bucket_name, Prefix=prefix, StartAfter=start_after):\n",
    "            for content in page.get('Contents', ()):\n",
    "                key = content['Key']\n",
    "                yield key\n",
    "\n",
    "    keys = list(keys(bucket, prefix=f\"{connector}\"))\n",
    "\n",
    "    # Compute the list of files to import in the proc\n",
    "    # For now we're just loading everything\n",
    "    files_to_load = [f\"@mystage/{k}\" for k in keys if \"pendulum\" not in k]\n",
    "    return files_to_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "938cfbd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [create or REPLACE stage mystage url = 's3://airbyte.alex']\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    }
   ],
   "source": [
    "# Create a stage to store the code\n",
    "create_stage_result = test_session.sql(f\"create or REPLACE stage mystage url = 's3://{bucket}'\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "00db06f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [ls '@mystage']\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [SELECT \"name\" FROM ( SELECT  *  FROM  TABLE ( RESULT_SCAN('01a76eec-0000-c321-00...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [select package_name, version from information_schema.packages where language='py...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [CREATE OR REPLACE PROCEDURE sync_connector_to_table(arg1 STRING,arg2 OBJECT) RET...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    }
   ],
   "source": [
    "# Internal stored procedure that will not be exposed to the consumer\n",
    "\n",
    "# pendulum has to be installed as a package for reasons...\n",
    "@sproc(packages=['snowflake-snowpark-python', 'pendulum', 'pandas'], imports=list_files_to_load(connector), name=\"sync_connector_to_table\", replace=True, is_permanent=True, stage_location=\"@mystage\")\n",
    "def compute(session: snowflake.snowpark.Session, to_table: str, config: dict) -> str:\n",
    "    from airbyte_cdk.models import ConfiguredAirbyteCatalog, ConfiguredAirbyteStream\n",
    "    from airbyte_cdk.models import SyncMode, DestinationSyncMode\n",
    "    import pandas as pd\n",
    "    from snowflake.snowpark.exceptions import SnowparkSQLException\n",
    "    from source_pokeapi import SourcePokeapi\n",
    "    logger = logging.getLogger(\"logger\")\n",
    "    source = SourcePokeapi()\n",
    "\n",
    "    catalog = source.discover(logger, config)\n",
    "    configured_catalog = ConfiguredAirbyteCatalog(\n",
    "        streams=[ConfiguredAirbyteStream(stream=s, sync_mode=SyncMode.full_refresh, destination_sync_mode=DestinationSyncMode.append) for s\n",
    "                 in catalog.streams])\n",
    "    \n",
    "    # hack: get the base url from the first stream...\n",
    "    base_url = source.streams(config)[0].url_base\n",
    "        \n",
    "    def patch_send(session):\n",
    "        import requests\n",
    "\n",
    "        def convert_request_to_external_function_input(request: requests.PreparedRequest):\n",
    "            body = request.body\n",
    "            headers = request.headers\n",
    "            url = request.url\n",
    "            return {\"body\": body, \"headers\": headers, \"url\": url}\n",
    "\n",
    "        def convert_external_function_output_to_response(output) -> requests.Response:\n",
    "            response = requests.Response()\n",
    "            response.status_code = 200\n",
    "            actual_output = list(output[0].as_dict().items())[0][1]\n",
    "            \n",
    "            response_as_json = json.loads(actual_output)\n",
    "            body = response_as_json[\"body\"]\n",
    "            \n",
    "            response._content = json.dumps(body).encode(\"ascii\")\n",
    "            return response\n",
    "\n",
    "        def new_session_send(self, request, **kwargs):\n",
    "            # convert to external function arguments\n",
    "            args = convert_request_to_external_function_input(request)\n",
    "\n",
    "            # call external function\n",
    "            if session:\n",
    "                #FIXME: No error handling...\n",
    "                path = \"/\" + args[\"url\"].replace(base_url, \"\")\n",
    "                try:\n",
    "                    output_from_external_function = session.sql(f\"select source_pokeapi_external_function('{args['body']}', '{path}');\").collect()\n",
    "                except SnowparkSQLException as e:\n",
    "                    print(dir(e))\n",
    "                    print(e)\n",
    "                    return e\n",
    "                response = convert_external_function_output_to_response(output_from_external_function)\n",
    "            else:\n",
    "                # This block is just fo testing...\n",
    "                content = b'{\"data\": \"hello\"}'\n",
    "                response = requests.Response()\n",
    "                response.status_code = 200\n",
    "                response._content = content\n",
    "            return response\n",
    "\n",
    "        requests.sessions.Session.send = new_session_send\n",
    "    patch_send(session)\n",
    "    \n",
    "    # Filter the columns to avoid running out of memory :(\n",
    "    keys_to_keep = [\"id\", \"name\", \"base_experience\", \"height\", \"weight\"]\n",
    "    for m in source.read(logger, config, configured_catalog, {}):\n",
    "        data = m.record.data\n",
    "        #filtered_data = dict((key, value) for key, value in data.items() if key in keys_to_keep)\n",
    "        session.sql(f\"insert into {to_table} select parse_json('{json.dumps(data)}')\").collect()\n",
    "        #session.create_dataframe([filtered_data]).write.mode('append').save_as_table(to_table)\n",
    "    return str(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ccbf9209",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [create table if not exists public.test_pokeapi (data variant)]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "INFO:snowflake.connector.cursor:query: [delete from public.test_pokeapi;]\n",
      "INFO:snowflake.connector.cursor:query execution done\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Row(number of rows deleted=0)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reset output table\n",
    "test_session.sql(\"create table if not exists public.test_pokeapi (data variant)\").collect()\n",
    "test_session.sql(\"delete from public.test_pokeapi;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78bd129b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:snowflake.connector.cursor:query: [CALL sync_connector_to_table('public.test_pokeapi', parse_json('{\"pokemon_name\":...]\n",
      "INFO:snowflake.connector.cursor:query execution done\n",
      "ERROR:snowflake.snowpark._internal.server_connection:Failed to execute query [queryID: None] CALL sync_connector_to_table('public.test_pokeapi', parse_json('{\"pokemon_name\": \"not_a_pokemon\"}'))\n",
      "100357 (P0000): None: Python Interpreter Error:\n",
      "Traceback (most recent call last):\n",
      "  File \"_udf_code.py\", line 7, in compute\n",
      "  File \"/var/folders/xx/m2btk9zx2436dd6nldyjtggh0000gn/T/ipykernel_24597/1876780594.py\", line 70, in compute\n",
      "  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 129, in read\n",
      "    raise e\n",
      "  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 115, in read\n",
      "    yield from self._read_stream(\n",
      "  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 184, in _read_stream\n",
      "    for record in record_iterator:\n",
      "  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 282, in _read_full_refresh\n",
      "    for record in records:\n",
      "  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 421, in read_records\n",
      "    response = self._send_request(request, request_kwargs)\n",
      "  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 339, in _send_request\n",
      "    return backoff_handler(user_backoff_handler)(request, request_kwargs)\n",
      "  File \"/home/udf/1404633461/backoff.zip/backoff/_sync.py\", line 105, in retry\n",
      "    ret = target(*args, **kwargs)\n",
      "  File \"/home/udf/1404633461/backoff.zip/backoff/_sync.py\", line 105, in retry\n",
      "    ret = target(*args, **kwargs)\n",
      "  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 293, in _send\n",
      "    self.logger.debug(\"Receiving response\", extra={\"headers\": response.headers, \"status\": response.status_code, \"body\": response.text})\n",
      "AttributeError: 'SnowparkSQLException' object has no attribute 'headers'\n",
      " in function SYNC_CONNECTOR_TO_TABLE with handler compute\n"
     ]
    },
    {
     "ename": "SnowparkSQLException",
     "evalue": "(1304): 100357 (P0000): None: Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 7, in compute\n  File \"/var/folders/xx/m2btk9zx2436dd6nldyjtggh0000gn/T/ipykernel_24597/1876780594.py\", line 70, in compute\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 129, in read\n    raise e\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 115, in read\n    yield from self._read_stream(\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 184, in _read_stream\n    for record in record_iterator:\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 282, in _read_full_refresh\n    for record in records:\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 421, in read_records\n    response = self._send_request(request, request_kwargs)\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 339, in _send_request\n    return backoff_handler(user_backoff_handler)(request, request_kwargs)\n  File \"/home/udf/1404633461/backoff.zip/backoff/_sync.py\", line 105, in retry\n    ret = target(*args, **kwargs)\n  File \"/home/udf/1404633461/backoff.zip/backoff/_sync.py\", line 105, in retry\n    ret = target(*args, **kwargs)\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 293, in _send\n    self.logger.debug(\"Receiving response\", extra={\"headers\": response.headers, \"status\": response.status_code, \"body\": response.text})\nAttributeError: 'SnowparkSQLException' object has no attribute 'headers'\n in function SYNC_CONNECTOR_TO_TABLE with handler compute",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSnowparkSQLException\u001b[0m                      Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtest_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msync_connector_to_table\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpublic.test_pokeapi\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpokemon_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnot_a_pokemon\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/session.py:1534\u001b[0m, in \u001b[0;36mSession.call\u001b[0;34m(self, sproc_name, *args)\u001b[0m\n\u001b[1;32m   1532\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCALL \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msproc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(sql_args)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1533\u001b[0m set_api_call_source(df, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSession.call[\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msproc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1534\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/telemetry.py:132\u001b[0m, in \u001b[0;36mdf_collect_api_telemetry.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39mquery_history() \u001b[38;5;28;01mas\u001b[39;00m query_history:\n\u001b[0;32m--> 132\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     api_calls \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;241m*\u001b[39margs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_plan\u001b[38;5;241m.\u001b[39mapi_calls,\n\u001b[1;32m    135\u001b[0m         {TelemetryField\u001b[38;5;241m.\u001b[39mNAME\u001b[38;5;241m.\u001b[39mvalue: \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    136\u001b[0m     ]\n\u001b[1;32m    137\u001b[0m     args[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_session\u001b[38;5;241m.\u001b[39m_conn\u001b[38;5;241m.\u001b[39m_telemetry_client\u001b[38;5;241m.\u001b[39msend_function_usage_telemetry(\n\u001b[1;32m    138\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    139\u001b[0m         TelemetryField\u001b[38;5;241m.\u001b[39mFUNC_CAT_ACTION\u001b[38;5;241m.\u001b[39mvalue,\n\u001b[1;32m    140\u001b[0m         api_calls\u001b[38;5;241m=\u001b[39mapi_calls,\n\u001b[1;32m    141\u001b[0m         sfqids\u001b[38;5;241m=\u001b[39m[q\u001b[38;5;241m.\u001b[39mquery_id \u001b[38;5;28;01mfor\u001b[39;00m q \u001b[38;5;129;01min\u001b[39;00m query_history\u001b[38;5;241m.\u001b[39mqueries],\n\u001b[1;32m    142\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/dataframe.py:451\u001b[0m, in \u001b[0;36mDataFrame.collect\u001b[0;34m(self, statement_params)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;129m@df_collect_api_telemetry\u001b[39m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcollect\u001b[39m(\n\u001b[1;32m    443\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, statement_params: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    444\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRow\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;124;03m\"\"\"Executes the query representing this DataFrame and returns the result as a\u001b[39;00m\n\u001b[1;32m    446\u001b[0m \u001b[38;5;124;03m    list of :class:`Row` objects.\u001b[39;00m\n\u001b[1;32m    447\u001b[0m \n\u001b[1;32m    448\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    449\u001b[0m \u001b[38;5;124;03m        statement_params: Dictionary of statement level parameters to be set while executing this action.\u001b[39;00m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_internal_collect_with_tag_no_telemetry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    452\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstatement_params\u001b[49m\n\u001b[1;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/dataframe.py:461\u001b[0m, in \u001b[0;36mDataFrame._internal_collect_with_tag_no_telemetry\u001b[0;34m(self, statement_params)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_internal_collect_with_tag_no_telemetry\u001b[39m(\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, statement_params: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    457\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m List[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRow\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    458\u001b[0m     \u001b[38;5;66;03m# When executing a DataFrame in any method of snowpark (either public or private),\u001b[39;00m\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;66;03m# we should always call this method instead of collect(), to make sure the\u001b[39;00m\n\u001b[1;32m    460\u001b[0m     \u001b[38;5;66;03m# query tag is set properly.\u001b[39;00m\n\u001b[0;32m--> 461\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    462\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_plan\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    463\u001b[0m \u001b[43m        \u001b[49m\u001b[43m_statement_params\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcreate_or_update_statement_params_with_query_tag\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    464\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstatement_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_session\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mquery_tag\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSKIP_LEVELS_THREE\u001b[49m\n\u001b[1;32m    465\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/server_connection.py:376\u001b[0m, in \u001b[0;36mServerConnection.execute\u001b[0;34m(self, plan, to_pandas, to_iter, **kwargs)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mexecute\u001b[39m(\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    369\u001b[0m     plan: SnowflakePlan,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    374\u001b[0m     List[Row], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, Iterator[Row], Iterator[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpandas.DataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    375\u001b[0m ]:\n\u001b[0;32m--> 376\u001b[0m     result_set, result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_result_set\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    377\u001b[0m \u001b[43m        \u001b[49m\u001b[43mplan\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    378\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    379\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m to_pandas:\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m result_set[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:148\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    144\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    145\u001b[0m     ne \u001b[38;5;241m=\u001b[39m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSQL_EXCEPTION_FROM_PROGRAMMING_ERROR(\n\u001b[1;32m    146\u001b[0m         e\n\u001b[1;32m    147\u001b[0m     )\n\u001b[0;32m--> 148\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ne\u001b[38;5;241m.\u001b[39mwith_traceback(tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/analyzer/snowflake_plan.py:81\u001b[0m, in \u001b[0;36mSnowflakePlan.Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrap\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     80\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m snowflake\u001b[38;5;241m.\u001b[39mconnector\u001b[38;5;241m.\u001b[39merrors\u001b[38;5;241m.\u001b[39mProgrammingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     83\u001b[0m         tb \u001b[38;5;241m=\u001b[39m sys\u001b[38;5;241m.\u001b[39mexc_info()[\u001b[38;5;241m2\u001b[39m]\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/server_connection.py:419\u001b[0m, in \u001b[0;36mServerConnection.get_result_set\u001b[0;34m(self, plan, to_pandas, to_iter, **kwargs)\u001b[0m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m holder, id_ \u001b[38;5;129;01min\u001b[39;00m placeholders\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    418\u001b[0m     final_query \u001b[38;5;241m=\u001b[39m final_query\u001b[38;5;241m.\u001b[39mreplace(holder, id_)\n\u001b[0;32m--> 419\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_query\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    420\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfinal_query\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    421\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_pandas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    422\u001b[0m \u001b[43m    \u001b[49m\u001b[43mto_iter\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mplan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqueries\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    423\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_ddl_on_temp_object\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    424\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    425\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m placeholders[query\u001b[38;5;241m.\u001b[39mquery_id_place_holder] \u001b[38;5;241m=\u001b[39m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    427\u001b[0m result_meta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cursor\u001b[38;5;241m.\u001b[39mdescription\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/server_connection.py:104\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    101\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    102\u001b[0m     )\n\u001b[1;32m    103\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[0;32m--> 104\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/server_connection.py:98\u001b[0m, in \u001b[0;36mServerConnection._Decorator.wrap_exception.<locals>.wrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_HAS_BEEN_CLOSED()\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ReauthenticationRequest \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m SnowparkClientExceptionMessages\u001b[38;5;241m.\u001b[39mSERVER_SESSION_EXPIRED(\n\u001b[1;32m    101\u001b[0m         ex\u001b[38;5;241m.\u001b[39mcause\n\u001b[1;32m    102\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/server_connection.py:333\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, **kwargs)\u001b[0m\n\u001b[1;32m    331\u001b[0m     query_id_log \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(ex, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    332\u001b[0m     logger\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to execute query\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery_id_log\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mex\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 333\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ex\n\u001b[1;32m    335\u001b[0m \u001b[38;5;66;03m# fetch_pandas_all/batches() only works for SELECT statements\u001b[39;00m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# We call fetchall() if fetch_pandas_all/batches() fails,\u001b[39;00m\n\u001b[1;32m    337\u001b[0m \u001b[38;5;66;03m# because when the query plan has multiple queries, it will\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;66;03m# have non-select statements, and it shouldn't fail if the user\u001b[39;00m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# calls to_pandas() to execute the query.\u001b[39;00m\n\u001b[1;32m    340\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m to_pandas:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/snowpark/_internal/server_connection.py:325\u001b[0m, in \u001b[0;36mServerConnection.run_query\u001b[0;34m(self, query, to_pandas, to_iter, is_ddl_on_temp_object, **kwargs)\u001b[0m\n\u001b[1;32m    323\u001b[0m         kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_statement_params\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m    324\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_statement_params\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSNOWPARK_SKIP_TXN_COMMIT_IN_DDL\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 325\u001b[0m results_cursor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_cursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    326\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnotify_query_listeners(\n\u001b[1;32m    327\u001b[0m     QueryRecord(results_cursor\u001b[38;5;241m.\u001b[39msfqid, results_cursor\u001b[38;5;241m.\u001b[39mquery)\n\u001b[1;32m    328\u001b[0m )\n\u001b[1;32m    329\u001b[0m logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecute query [queryID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresults_cursor\u001b[38;5;241m.\u001b[39msfqid\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/connector/cursor.py:804\u001b[0m, in \u001b[0;36mSnowflakeCursor.execute\u001b[0;34m(self, command, params, _bind_stage, timeout, _exec_async, _no_retry, _do_reset, _put_callback, _put_azure_callback, _put_callback_output_stream, _get_callback, _get_azure_callback, _get_callback_output_stream, _show_progress_bar, _statement_params, _is_internal, _describe_only, _no_results, _is_put_get, _raise_put_get_error, _force_put_overwrite, file_stream)\u001b[0m\n\u001b[1;32m    800\u001b[0m     is_integrity_error \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    801\u001b[0m         code \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m100072\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    802\u001b[0m     )  \u001b[38;5;66;03m# NULL result in a non-nullable column\u001b[39;00m\n\u001b[1;32m    803\u001b[0m     error_class \u001b[38;5;241m=\u001b[39m IntegrityError \u001b[38;5;28;01mif\u001b[39;00m is_integrity_error \u001b[38;5;28;01melse\u001b[39;00m ProgrammingError\n\u001b[0;32m--> 804\u001b[0m     \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler_wrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/connector/errors.py:276\u001b[0m, in \u001b[0;36mError.errorhandler_wrapper\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    253\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    254\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21merrorhandler_wrapper\u001b[39m(\n\u001b[1;32m    255\u001b[0m     connection: SnowflakeConnection \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    258\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mint\u001b[39m],\n\u001b[1;32m    259\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    260\u001b[0m     \u001b[38;5;124;03m\"\"\"Error handler wrapper that calls the errorhandler method.\u001b[39;00m\n\u001b[1;32m    261\u001b[0m \n\u001b[1;32m    262\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m        exception to the first handler in that order.\u001b[39;00m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 276\u001b[0m     handed_over \u001b[38;5;241m=\u001b[39m \u001b[43mError\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhand_to_other_handler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m        \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m handed_over:\n\u001b[1;32m    283\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m Error\u001b[38;5;241m.\u001b[39merrorhandler_make_exception(\n\u001b[1;32m    284\u001b[0m             error_class,\n\u001b[1;32m    285\u001b[0m             error_value,\n\u001b[1;32m    286\u001b[0m         )\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/connector/errors.py:331\u001b[0m, in \u001b[0;36mError.hand_to_other_handler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    329\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cursor \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    330\u001b[0m     cursor\u001b[38;5;241m.\u001b[39mmessages\u001b[38;5;241m.\u001b[39mappend((error_class, error_value))\n\u001b[0;32m--> 331\u001b[0m     \u001b[43mcursor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merrorhandler\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconnection\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcursor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_class\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_value\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    332\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/Library/Python/3.8/lib/python/site-packages/snowflake/connector/errors.py:210\u001b[0m, in \u001b[0;36mError.default_errorhandler\u001b[0;34m(connection, cursor, error_class, error_value)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdefault_errorhandler\u001b[39m(\n\u001b[1;32m    194\u001b[0m     connection: SnowflakeConnection,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    197\u001b[0m     error_value: \u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mstr\u001b[39m],\n\u001b[1;32m    198\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m     \u001b[38;5;124;03m\"\"\"Default error handler that raises an error.\u001b[39;00m\n\u001b[1;32m    200\u001b[0m \n\u001b[1;32m    201\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[38;5;124;03m        A Snowflake error.\u001b[39;00m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error_class(\n\u001b[1;32m    211\u001b[0m         msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmsg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    212\u001b[0m         errno\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merrno\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    213\u001b[0m         sqlstate\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msqlstate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    214\u001b[0m         sfqid\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msfqid\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    215\u001b[0m         done_format_msg\u001b[38;5;241m=\u001b[39merror_value\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdone_format_msg\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m    216\u001b[0m         connection\u001b[38;5;241m=\u001b[39mconnection,\n\u001b[1;32m    217\u001b[0m         cursor\u001b[38;5;241m=\u001b[39mcursor,\n\u001b[1;32m    218\u001b[0m     )\n",
      "\u001b[0;31mSnowparkSQLException\u001b[0m: (1304): 100357 (P0000): None: Python Interpreter Error:\nTraceback (most recent call last):\n  File \"_udf_code.py\", line 7, in compute\n  File \"/var/folders/xx/m2btk9zx2436dd6nldyjtggh0000gn/T/ipykernel_24597/1876780594.py\", line 70, in compute\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 129, in read\n    raise e\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 115, in read\n    yield from self._read_stream(\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 184, in _read_stream\n    for record in record_iterator:\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/abstract_source.py\", line 282, in _read_full_refresh\n    for record in records:\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 421, in read_records\n    response = self._send_request(request, request_kwargs)\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 339, in _send_request\n    return backoff_handler(user_backoff_handler)(request, request_kwargs)\n  File \"/home/udf/1404633461/backoff.zip/backoff/_sync.py\", line 105, in retry\n    ret = target(*args, **kwargs)\n  File \"/home/udf/1404633461/backoff.zip/backoff/_sync.py\", line 105, in retry\n    ret = target(*args, **kwargs)\n  File \"/home/udf/1404633461/airbyte_cdk.zip/airbyte_cdk/sources/streams/http/http.py\", line 293, in _send\n    self.logger.debug(\"Receiving response\", extra={\"headers\": response.headers, \"status\": response.status_code, \"body\": response.text})\nAttributeError: 'SnowparkSQLException' object has no attribute 'headers'\n in function SYNC_CONNECTOR_TO_TABLE with handler compute"
     ]
    }
   ],
   "source": [
    "test_session.call(\"sync_connector_to_table\", \"public.test_pokeapi\", {\"pokemon_name\": \"not_a_pokemon\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63f57be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.call(\"sync_connector_to_table\", \"public.test_pokeapi\", {\"pokemon_name\": \"articuno\"})\n",
    "test_session.call(\"sync_connector_to_table\", \"public.test_pokeapi\", {\"pokemon_name\": \"zapdos\"})\n",
    "test_session.call(\"sync_connector_to_table\", \"public.test_pokeapi\", {\"pokemon_name\": \"moltres\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acccf096",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"select * from public.test_pokeapi\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "605993e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"create table if not exists source_pokeapi_app.app_schema.configs (consumer_id varchar, output_table varchar, config variant);\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e09a6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's insert and read a config to/from a table\n",
    "def insert_or_update_config(config_table, consumer_id, output_table, config):\n",
    "    test_session.sql(f\"\"\"\n",
    "    merge into {config_table} a using (select '{consumer_id}' as consumer_id, '{output_table}' as output_table, parse_json('{json.dumps(config)}') as config) as b on a.CONSUMER_ID=b.CONSUMER_ID\n",
    "      when matched then update set a.config=b.config\n",
    "      when not matched then insert (consumer_id, output_table, config) values (b.CONSUMER_ID, b.output_table, b.config);\n",
    "\"\"\").collect()\n",
    "insert_or_update_config(\"source_pokeapi_app.app_schema.configs\", 'id0', \"public.test_pokeapi\", {\"pokemon_name\": \"abomasnow\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63f2f82",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"select * from source_pokeapi_app.app_schema.configs;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc0a7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal stored procedure that will not be exposed to the consumer\n",
    "\n",
    "# pendulum has to be installed as a package for reasons...\n",
    "@sproc(packages=['snowflake-snowpark-python', 'pendulum', 'pandas'], name=\"sync_consumer_id\", replace=True, is_permanent=True, stage_location=\"@mystage\")\n",
    "def compute_consumer(session: snowflake.snowpark.Session, consumer_id: str) -> str:\n",
    "    row = session.sql(f\"select output_table, config from source_pokeapi_app.app_schema.configs where consumer_id = '{consumer_id}';\").collect()[0]\n",
    "    output_table = row[\"OUTPUT_TABLE\"]\n",
    "    config = json.loads(row[\"CONFIG\"])\n",
    "    return session.call(\"sync_connector_to_table\", output_table, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18662aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.call(\"sync_consumer_id\", \"id0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "195ce569",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"select * from public.test_pokeapi\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17576eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"delete from source_pokeapi_app.app_schema.configs\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba6bcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedure that WILL BE exposed to the consumer\n",
    "\n",
    "# pendulum has to be installed as a package for reasons...\n",
    "@sproc(packages=['snowflake-snowpark-python', 'pendulum', 'pandas'], name=\"register_config\", replace=True, is_permanent=True, stage_location=\"@mystage\")\n",
    "def register_config(session: snowflake.snowpark.Session, consumer_id: str, config: dict, output_table: str) -> str:\n",
    "    def insert_or_update_config(session, config_table, consumer_id, output_table, config):\n",
    "        session.sql(f\"\"\"\n",
    "        merge into {config_table} a using (select '{consumer_id}' as consumer_id, '{output_table}' as output_table, parse_json('{json.dumps(config)}') as config) as b on a.CONSUMER_ID=b.CONSUMER_ID\n",
    "          when matched then update set a.config=b.config\n",
    "          when not matched then insert (consumer_id, output_table, config) values (b.CONSUMER_ID, b.output_table, b.config);\n",
    "    \"\"\").collect()\n",
    "    insert_or_update_config(session, \"source_pokeapi_app.app_schema.configs\", consumer_id, output_table, config)\n",
    "    return \"REGISTER SUCCESS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "034193fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Procedule that WILL BE exposed to the consumer\n",
    "\n",
    "# pendulum has to be installed as a package for reasons...\n",
    "@sproc(packages=['snowflake-snowpark-python', 'pendulum', 'pandas'], name=\"schedule_job\", replace=True, is_permanent=True, stage_location=\"@mystage\")\n",
    "def schedule_job(session: snowflake.snowpark.Session, consumer_id: str, warehouse_name: str) -> str:\n",
    "    create_task_command = f\"\"\"\n",
    "    CREATE OR REPLACE TASK sync warehouse = \"{warehouse_name}\"\n",
    "    SCHEDULE = '5 MINUTE'\n",
    "    as call sync_consumer_id('{consumer_id}')\n",
    "    \"\"\"\n",
    "    session.sql(create_task_command).collect()\n",
    "    return \"REGISTER SUCCESS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating DB roles for the Snowflake Native Application\n",
    "database_role = \"source_pokeapi_app.shared_db_role\"\n",
    "print(test_session.sql(f\"create or replace database role {database_role}\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f5800fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grant usage\n",
    "print(test_session.sql(f\"grant usage on database source_pokeapi_app to database role {database_role};\").collect())\n",
    "print(test_session.sql(f\"grant usage on schema source_pokeapi_app.app_schema to database role {database_role};\").collect())\n",
    "print(test_session.sql(f\"grant usage on procedure register_config(string, object, string) to database role {database_role}\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "635ae430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create hiddent db role\n",
    "hidden_db_role = \"source_pokeapi_app.hidden_db_role\"\n",
    "print(test_session.sql(f\"create or replace database role {hidden_db_role}\").collect())\n",
    "print(test_session.sql(f\"grant usage on database source_pokeapi_app to database role {hidden_db_role}\").collect())\n",
    "print(test_session.sql(f\"grant usage on schema source_pokeapi_app.app_schema to database role {hidden_db_role};\").collect())\n",
    "print(test_session.sql(f\"grant usage on procedure sync_consumer_id(string) to database role {hidden_db_role};\").collect())\n",
    "print(test_session.sql(f\"grant usage on procedure sync_connector_to_table(string, object) to database role {hidden_db_role};\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d917c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.call(\"SOURCE_POKEAPI_APP.APP_SCHEMA.register_config\", \"id0\", {\"pokemon_name\": \"articuno\"}, \"public.test_pokeapi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a20a122",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"describe procedure sync_consumer_id(string)\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75f645e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.call(\"schedule_job\", \"id0\", \"COMPUTE_WH\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5309b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"describe task sync\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "921866b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"ALTER TASK sync resume;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9280602",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"describe task sync\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c61751a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"select * from source_pokeapi_app.app_schema.configs\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e66fb4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an installer script\n",
    "# FIXME: I think the schema should be specific to the connector...\n",
    "test_session.sql(f\"\"\"\n",
    "CREATE OR REPLACE PROCEDURE source_pokeapi_app.app_schema.installer()\n",
    "RETURNS STRING\n",
    "LANGUAGE SQL\n",
    "EXECUTE AS OWNER\n",
    "AS $$\n",
    "  begin\n",
    "    return 'installer script Done';\n",
    "  end;\n",
    "$$;\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edca79df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup a share for the application\n",
    "test_session.sql(f\"\"\"\n",
    "CREATE SHARE IF NOT EXISTS source_pokeapi_share installer = source_pokeapi_app.app_schema.installer();\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aab47da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add objects to the share\n",
    "print(test_session.sql(f\"\"\"grant usage on database source_pokeapi_app to share source_pokeapi_share;\"\"\").collect())\n",
    "print(test_session.sql(f\"\"\"grant usage on schema source_pokeapi_app.app_schema to share source_pokeapi_share;\"\"\").collect())\n",
    "print(test_session.sql(f\"\"\"grant usage on procedure source_pokeapi_app.app_schema.installer() to share source_pokeapi_share;\"\"\").collect())\n",
    "print(test_session.sql(f\"\"\"grant database role source_pokeapi_app.hidden_db_role to share source_pokeapi_share;\"\"\").collect())\n",
    "print(test_session.sql(f\"\"\"grant database role source_pokeapi_app.shared_db_role to share source_pokeapi_share;\"\"\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ba8f4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_session.sql(\n",
    "    f\"ALTER share source_pokeapi_share ADD ACCOUNTS = yp50190;\"\n",
    ").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ededca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open customer session...\n",
    "with open(\"./secrets/yp50190.json\", \"r\") as f:\n",
    "    connection_parameters = json.loads(f.read())\n",
    "customer_session = Session.builder.configs(connection_parameters).create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd06f59e",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_session.sql(\"create database customer_pokeapi_db from share GZ45853.source_pokeapi_app;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d0a10a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2500c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# following the tutorial\n",
    "test_session.sql(\"CREATE DATABASE time_app;\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29b8ad24",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_session.sql(\"CREATE SCHEMA time_app.app_schema\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb44fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create stored procedure\n",
    "test_session.sql(\"\"\"\n",
    "CREATE PROCEDURE time_app.app_schema.record_time()\n",
    "RETURNS STRING\n",
    "LANGUAGE SQL\n",
    "EXECUTE AS OWNER\n",
    "AS $$\n",
    "  begin\n",
    "      INSERT INTO time_schema.time_table VALUES(CURRENT_TIMESTAMP);\n",
    "      return 'CURRENT TIMESTAMP RECORDED';\n",
    "  end;\n",
    "\n",
    "$$;\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7da2195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create procedure that will be exposed to the consumer\n",
    "test_session.sql(\n",
    "\"\"\"\n",
    "CREATE PROCEDURE time_app.app_schema.start_service(wh_name string)\n",
    "\n",
    "RETURNS STRING\n",
    "LANGUAGE JAVASCRIPT\n",
    "EXECUTE AS OWNER\n",
    "AS $$\n",
    "\n",
    "var create_task_cmd =\n",
    "     \"CREATE TASK IF NOT EXISTS time_schema.insert_time warehouse = \"\n",
    "        + WH_NAME\n",
    "        + \" SCHEDULE = '5 MINUTE'\"\n",
    "        + \" as call app_schema.record_time()\";\n",
    "\n",
    "snowflake.execute({ sqlText: create_task_cmd });\n",
    "\n",
    "snowflake.execute({ sqlText: `ALTER TASK time_schema.insert_time resume` });\n",
    "\n",
    "return \"SERVICE STARTED\";\n",
    "\n",
    "$$;\n",
    "\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa51c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create db roles for the native app\n",
    "command = \"\"\"\n",
    "CREATE or replace DATABASE ROLE time_app.shared_db_role;\n",
    "\n",
    "GRANT USAGE ON DATABASE time_app TO\n",
    "DATABASE ROLE time_app.shared_db_role;\n",
    "\n",
    "GRANT USAGE ON SCHEMA time_app.app_schema TO\n",
    "DATABASE ROLE time_app.shared_db_role;\n",
    "\n",
    "GRANT USAGE ON PROCEDURE time_app.app_schema.start_service(string)\n",
    "TO DATABASE ROLE time_app.shared_db_role;\n",
    "\n",
    "CREATE or replace DATABASE ROLE time_app.hidden_db_role;\n",
    "\n",
    "GRANT USAGE ON DATABASE time_app TO\n",
    "DATABASE ROLE time_app.hidden_db_role;\n",
    "\n",
    "GRANT USAGE ON SCHEMA time_app.app_schema TO\n",
    "DATABASE ROLE time_app.hidden_db_role;\n",
    "\n",
    "GRANT USAGE ON PROCEDURE time_app.app_schema.record_time() TO\n",
    "DATABASE ROLE time_app.hidden_db_role;\"\"\"\n",
    "\n",
    "for c in command.split(\";\"):\n",
    "    if c:\n",
    "        print(f\"command: {c}\")\n",
    "        print(test_session.sql(c).collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2978c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installer script\n",
    "test_session.sql(\"\"\"\n",
    "CREATE PROCEDURE time_app.app_schema.installer()\n",
    "RETURNS STRING\n",
    "LANGUAGE SQL\n",
    "EXECUTE AS OWNER\n",
    "AS $$\n",
    "  begin\n",
    "    CREATE SCHEMA time_schema;\n",
    "    CREATE TABLE time_schema.time_table(ts timestamp);\n",
    "    GRANT USAGE ON schema time_schema TO DATABASE ROLE APP_EXPORTER;\n",
    "    GRANT SELECT ON TABLE time_schema.time_table TO\n",
    "    DATABASE ROLE APP_EXPORTER;\n",
    "    GRANT DATABASE ROLE shared_db_role TO DATABASE ROLE APP_EXPORTER;\n",
    "    return 'installer script Done';\n",
    "  end;\n",
    "$$;\n",
    "\"\"\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fbcff8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create share\n",
    "test_session.sql(\"CREATE SHARE time_app_share installer = time_app.app_schema.installer();\").collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b80081",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_session.sql(\"GRANT USAGE ON DATABASE time_app TO SHARE time_app_share;\").collect())\n",
    "print(test_session.sql(\"GRANT USAGE ON SCHEMA time_app.app_schema TO SHARE time_app_share;\").collect())\n",
    "print(test_session.sql(\"GRANT USAGE ON PROCEDURE time_app.app_schema.installer() TO SHARE time_app_share;\").collect())\n",
    "print(test_session.sql(\"GRANT DATABASE ROLE time_app.hidden_db_role TO SHARE time_app_share;\").collect())\n",
    "print(test_session.sql(\"GRANT DATABASE ROLE time_app.shared_db_role TO SHARE time_app_share;\").collect())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eb631c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
